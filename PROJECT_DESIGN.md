# Application Workflow

Because of the multiple API / LLM calls across multiple jobs, the application workflow need to be event based and parallel.  This will also help drive better reporting to the UI front-end, to keep user informed of the current application activity. 

## Folder Structure and Naming (`job folder`)

The `job folder` is used to contain all files relevent to the job posting.  By providing detailed folder naming, it simplifies the naming of filed contained.  The job folder requires some information about the job in order to be created.

Job folders are named using the following convention: 
`jobs/{phase}/{company}.{title}.{date}.{id}/`
Where:
- `{phase}` = current job phase, 1_Queued, 2_Review, 3_Processed, 4_Complete
- `{company}` = company name
- `{title}` = job title
- `{date}` = date job was posted
- `{id}` = unique job identifier

All fields are delimited by a period `.` character

For example, the folder:  `jobs/1_Queued/AcmeCorp.VPCustomerSuccess.20260113-123459.987654321/`
- The job id is: `987654321`
- The job posted date is: `20260113-123459` aka 2026-01-13 12:34:59 PST
- The job title is: `VPCustomerSuccess` aka VP Customer Success
- The job company is: `AcmeCorp` aka Acme Corporation
- The job current in phase: `1_Queued` (parent folder)

The job folder name can be validated / corrected at any time by examining the job.yaml file it contains, which contain the id / date / title / company.

Note that the phase folder name have capital letters, allowing the UI to dynamically use those names directly (minus the leading number and underscore). 

## File Names and Structures

The files expected in the job folder are as follows:

### Phase: 1_Queued 

Queued jobs have been created by either:
- automated email collector, or 
- manually entered by user, or 
- via a manually supplied URL to pull and consume

However the data is generated, it has been pulled and is ready for review by the user.  From here, a user may choose to 'generate' a custom resume / cover letter, use a static (non-custom) resume with custom cover letter, or can elect to skip the job entirely, which simply moves the collateral to '9_Skipped' folder. 

Generated Files:
- job.html = If the job is automatically pulled from an email / website, this is the entire job posting html, unmodified.  If manually entered by user, this file can be omitted.
- job.yaml = (required) Structured data about the job opportunity, either entered manually, or automatically generated from job.html.  This must strictly adhere to `src/lib/templates/job.yaml`, and must exist in order to move to the next phase. 
- job.log = Log file containing all actions taken on this job, and all API calls made.  This is primarily for debugging and reporting to the user, and will be continually appended to as the job traverses the various phases.

### Phase: 2_Data Generated

This phase holds data files generated by the merging of the resume.yaml and the job.yaml files.  This generation can be from the AI process, the static resume process, or even custom generation of files outside this application. Regardless of how they're generated, the data files should now exist in .yaml files.

Its at this stage users can review the data and make corrections, before being combined into the final resume / cover letter docs.

Required Files:
- job.yaml 

Generated Files: 
- subcontent.summary.yaml = the post-generation 'summary' content
- subcontent.skills.yaml = the post-generation 'skills' content
- subcontent.highlights.yaml = the post-generation 'highlights' content
- subcontent.experience.yaml = the post-generation 'experience' content
- subcontent.education.yaml = the post-generation 'education' content
- subcontent.awards.yaml = the post-generation 'awards' content
- subcontent.coverletter.yaml = the post-generation 'coverletter' content

Appended Files:
- job.log
  
Once all subcontent.*.yaml files have been generated, the job can be moved to the `3_Docs Generated` phase.

### Phase: 3_Docs Generated

This phase combines all `subcontent.*.yaml` files into the final resume and cover letter.  

Required Files:
- job.yaml 
- subcontent.summary.yaml  
- subcontent.skills.yaml  
- subcontent.highlights.yaml  
- subcontent.experience.yaml  
- subcontent.education.yaml  
- subcontent.awards.yaml  
- subcontent.coverletter.yaml  
  
Generated Files: 
- resume.html = Combined information from all the `subcontent.*.yaml` files into a single formatted resume html 
- resume.pdf = a PDF of `resume.html`
- coverletter.html = Formatted from `subcontent.coverletter.yaml` into a final formatted cover letter html
- coverletter.pdf = a PDF of `coverletter.html`

Appended Files:
- job.log


### Phase: 4_Applied, 5_FollowUp, 6_Interviewing, 7_Negotiating, 8_Accepted

These phases are for tracking progress in the overall job hunting process, they do not modify files.  The user can ask to move the job folder to any one of these phases.

Appended Files:
- job.log

### Phase: Skipped

This is a special phase, to collect jobs that the user believes are not worth the time to apply.   The user can elect to Skip a job from any other phase, but most often this will happen from the Queued phase, where the user decides the location / pay / position doesn't match their search criteria. 

There are no file requirements, nor are any generated.

Appended Files:
- job.log

### Phase: Expired

This is a special phase for jobs that have "aged out", aka where the date in the job.yaml file in the `1_Queued` phase is more than 45 days old.  This happens via automatic maintenance, to keep the queue clean and relevant.

Appended Files:
- job.log

### Phase: Errored

This is a special phase for jobs that have failed at some point in the process.  The user can elect to re-try the job, sending it back to the phase prior to where it errored.  When the error occured, a log file should be generated describing the error, and in which phase it occurred, so the application knows where to retry.  This also provides a single folder to monitor for errors, and a point start developing automated retry logic, based on the log file description. 

Generated Files: 
- error.md = Technically generated at error time, this file contains details on the error, what happened before / after, and importantly what phase / process was running when the error occured.

Appended Files:
- job.log


# Event Based Framework 

This very simple event framework will accept a job folder Path object, and an event name indicating what task or function to perform on that collection of data files. 
The task will return a Success boolean, and the current job folder Path object (new or same job folder path, depending on whether a phase change occurred).  If there is any error, the function will return False and the current location of the job folder, which depending on the severity of the error, could be in the `jobs/Errored/` phase. 

By convention, Event names are in the format `{verb}_{content}...` to help organize the various functions.   Each event name corresponds to a python file of the same name, which will contain a function called `execute()`.  

As an example only: the code to move a job folder to "5_FollowUp/" is:
```python 
from pathlib import Path
import src.events.move_followup 

success, new_job_folder = move_followup.execute( Path('jobs/4_Applied/co.job.date.id/') )
if success:
    print( new_job_folder ) # returns 'jobs/5_FollowUp/co.job.date.id/'
```

Practically, the events system allows for a simple way to call functions based on a string name, and pass the job folder path to the function.  Thus, the real code to execute the above example will be a function call to the event framework, not calling the code directly. 

This allows us an easy way to extend functionality, as new features can be added by simply creating a new file in the `src/events/` folder, with the appropriate name, and an `execute()` function within.

The file may also contain helper functions, constants, etc. that are used by the execute function. In addition to an `execute()` function, there should also be a `test` function that can run tests on the functionality without damaging real working files. The event framework itself should include a "test" flag, that changes the call from `execute()` to `test()` and tracks success / failures for follow-up.

Note that events can call other events.  The `log_message` and `notify_user` events are probably the most common, as all events should logged, and important notifications should be sent to the UI.  All events are async / run in parallel. 
 
## Events

- **log_message** = appends a message to the job.log file, in the format of `{YYYY-MM-DD HH:MM:SS} - {job_folder_name} - {message}`. 
- **notify_user** = sends a message to the user via a transient UI notification (aka Toast Notification), as well as calling log_message with the same info. The Toast notification should always include the `{job_folder_name}` in case there are multiple activies / jobs in progress.
- **create_jobfolder** = generates a new job folder in `1_Queued/` based on the input folder path, meaning the new folder name must already have been generated based on the job data. If the job folder already exists, the folder path is returned as expected, but the success boolean is set to False; it is only True if the folder was actually created. 

- **get_gmail_linkedin** = connects to gmail and searches / downloads emails with subject "LinkedIn Job Alert" from Linkedin.com, sent in the last 2 weeks, then iterates over the jobs found within the email html body to generate new job folders and job.yaml files in `1_Queued/`.  The data in job.yaml may be incomplete at this step, but the company, title, date, and id should all be available in the email html body, as well as the `url` to get the description (`https://www.linkedin.com/jobs/view/{id}`), and salary, location, tags, etc. 
- **get_url** = retrieves the HTML body from the job.yaml `url` field, saves the HTML to job.html, and creates or augments the job.yaml (depending on whether it exists). There may be multiple sub-functions, one per domain name; i.e., linkedin.com, monster.com, indeed.com, etc. as they will likely have different html structures. The sub-function selected can come from the url's domain. Note; the url should not require authentication.  For example, the non-auth LinkedIn url is: `https://www.linkedin.com/jobs/view/{id}`

- **move_queue** = will move the job folder to the '1_Queued' folder / phase
- **move_data_gen** = will move the job folder to the '2_Data Generated' folder / phase
- **move_docs_gen** = will move the job folder to the '3_Docs Generated' folder / phase
- **move_applied** = will move the job folder to the '4_Applied' folder / phase
- **move_followup** = will move the job folder to the '5_FollowUp' folder / phase
- **move_interviewing** = will move the job folder to the '6_Interviewing' folder / phase
- **move_negotiating** = will move the job folder to the '7_Negotiating' folder / phase
- **move_accepted** = will move the job folder to the '8_Accepted' folder / phase
- **move_skipped** = will move the job folder to the 'Skipped' folder / phase
- **move_expired** = will move the job folder to the 'Expired' folder / phase
- **move_errored** = will move the job folder to the 'Errored' folder / phase

- **gen_llm_subcontent_summary** = uses the job.yaml, resume.yaml, and configured LLM to generate the subcontent.summary.yaml file 
- **gen_llm_subcontent_skills** =  uses the job.yaml, resume.yaml, and configured LLM to generate the subcontent.skills.yaml file 
- **gen_llm_subcontent_highlights** = uses the job.yaml, resume.yaml, and configured LLM to generate the subcontent.highlights.yaml file 
- **gen_llm_subcontent_experience** = uses the job.yaml, resume.yaml, and configured LLM to generate the subcontent.experience.yaml file 
- **gen_llm_subcontent_education** = uses the job.yaml, resume.yaml, and configured LLM to generate the subcontent.education.yaml file 
- **gen_llm_subcontent_awards** = uses the job.yaml, resume.yaml, and configured LLM to generate the subcontent.awards.yaml file 
- **gen_llm_subcontent_coverletter** = uses the job.yaml, resume.yaml, and configured LLM to generate the subcontent.coverletter.yaml file 
- **gen_static_subcontent_summary** = uses the resume.yaml section verbatium, and saves it to subcontent.summary.yaml for custom editing as needed
- **gen_static_subcontent_skills** =  uses the resume.yaml section verbatium, and saves it to subcontent.skills.yaml for custom editing as needed
- **gen_static_subcontent_highlights** = uses the resume.yaml section verbatium, and saves it to subcontent.highlights.yaml for custom editing as needed
- **gen_static_subcontent_experience** = uses the resume.yaml section verbatium, and saves it to subcontent.experience.yaml for custom editing as needed
- **gen_static_subcontent_education** = uses the resume.yaml section verbatium, and saves it to subcontent.education.yaml for custom editing as needed
- **gen_static_subcontent_awards** = uses the resume.yaml section verbatium, and saves it to subcontent.awards.yaml for custom editing as needed
- **gen_static_subcontent_coverletter** = uses the resume.yaml section verbatium, and saves it to subcontent.coverletter.yaml for custom editing as needed

- **gen_resume_html** = combines all subcontent.*.yaml files into a single resume.html file, and saves, overwriting existing without warning 
- **gen_resume_pdf** = converts resume.html to resume.pdf, and saves, overwriting existing without warning 
- **gen_coverletter_html** = combines subcontent.coverletter.yaml into coverletter.html and saves, overwriting existing without warning 
- **gen_coverletter_pdf** = converts coverletter.html to coverletter.pdf and saves, overwriting existing without warning 

- **batch_gen_data** = will run all the gen_llm_subcontent_* and gen_static_subcontent_* functions in parallel, and save the results to the subcontent.*.yaml files, with a final sequential function to [ move_data_gen ].  This is the function that will be called when the user elects to generate data for an entire queued job.
- **batch_gen_docs** = will run functions in sequence: [gen_resume_html, gen_coverletter_html, gen_resume_pdf, gen_coverletter_pdf, move_docs_gen], and save the results to the final documents.  This is the function that will be called when the user elects to generate docs for an entire data generated job.

- **upload_s3** = uploads resume.pdf and coverletter.pdf to s3 bucket, set in the .env file (S3_RESUME_BUCKET).  To avoid name collisions, the files will be save to S3 as `resume.{id}.pdf` and `coverletter.{id}.pdf`. 

Other events can be added as needed, by simply adding the new python file to `src/events/*.py` with `execute()` and `test()` functions. 


# Project Structure

Here is the file structure of the project.   Most uses are detailed above, but a few notes:
- the `src/logs/` folder contains the daily **application** logs, named by date, and rolled over daily.  This is different than the job-specific logs, which are stored in the appropriate job folder directly.
- `src/templates/` folder contains templates / defaults for data files, such as job.yaml, resume.yaml, etc. These can also be used for validation purposes. 
- `src/ui/` folder contains the web application code, including the flask app, routes, templates, and static files.
- `tests/` folder contains the unit tests for the events, library functions, and web UI.
- `.venv_resumai/` is the python virtual environment
- `requirements.txt` file contains the list of python packages required for the application to run.
- `run_webserver.sh` file contains the command to activate the venv and run the python web application.



```
job-application-automation/
├── README.md
├── requirements.txt
├── .env.example
├── .venv_resumai
├── jobs/
│   ├── 1_Queued/
│   ├── 2_Data Generated/
│   ├── 3_Docs Generated/
│   ├── 4_Applied/
│   ├── 5_FollowUp/
│   ├── 6_Interviewing/
│   ├── 7_Negotiating/
│   ├── 8_Accepted/
│   ├── Skipped/
│   ├── Expired/
│   └── Errored/
├── resumes/
│   ├── stephen_hilton.yaml
│   ├── susy_creamcheese.yaml
│   └── ... etc.
├── src/
│   ├── events/
│   │   ├── log_message.py
│   │   ├── notify_user.py
│   │   ├── create_jobfolder.py
│   │   ├── get_gmail_linkedin.py
│   │   ├── get_url.py
│   │   ├── move_queue.py
│   │   └── ... etc.
│   ├── logs/ 
│   │   ├── 20251024.applog.txt 
│   │   ├── 20251025.applog.txt 
│   │   ├── 20251026.applog.txt 
│   │   └── ... etc.
│   ├── templates/
│   │   ├── job.yaml
│   │   ├── resume.yaml
│   │   └── ... etc.
│   └── ui/
│       ├── static/
│       │   ├── css/
│       │   ├── js/
│       │   └── images/
│       ├── templates/
│       │   ├── base.html
│       │   ├── dashboard.html
│       │   ├── job_detail.html
│       │   └── settings.html
│       └── app.py
└── test/
    ├── test_utils.py
    ├── test_src/
    │   └── test_*.py
    ├── test_src_events/
    │   └── test_*.py 
    └── test_src_ui/
        └── test_*.py
```